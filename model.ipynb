{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "from datagenerator_creation import DataGenerator\n",
    "from build_model import build_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "from utils import getLettersAndDiacritics, convert_to_two_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, split_at=.3):\n",
    "    m = len(df)\n",
    "    split_point = int((1-split_at)*m)\n",
    "\n",
    "    train = \"\".join(df['Bayt_Text'][:split_point])\n",
    "    val = \"\".join(df['Bayt_Text'][split_point:])\n",
    "\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/cleaned_arabic_dataset.csv'\n",
    "df = pd.read_csv(path)\n",
    "train, val = split_data(df[:1000])\n",
    "\n",
    "train_generator = DataGenerator(train)\n",
    "val_generator = DataGenerator(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 128)           87552     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 42)                10794     \n",
      "=================================================================\n",
      "Total params: 492,586\n",
      "Trainable params: 492,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Loading Weights...')\n",
    "# weights_path = 'weights/my_model_weights2.h5'\n",
    "# model = load_weights(model, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "216/216 [==============================] - 59s 273ms/step - loss: 4.2149 - val_loss: 4.1180\n",
      "Epoch 2/5\n",
      "216/216 [==============================] - 50s 232ms/step - loss: 4.0291 - val_loss: 3.8363\n",
      "Epoch 3/5\n",
      "216/216 [==============================] - 45s 210ms/step - loss: 3.8249 - val_loss: 3.7261\n",
      "Epoch 4/5\n",
      "216/216 [==============================] - 45s 208ms/step - loss: 3.7056 - val_loss: 3.6016\n",
      "Epoch 5/5\n",
      "216/216 [==============================] - 45s 209ms/step - loss: 3.5730 - val_loss: 3.5629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c154e0e3c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                validation_data=val_generator,\n",
    "                use_multiprocessing=True,\n",
    "                workers=3,\n",
    "                epochs=5,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_vec_to_char(two_hot_vec):\n",
    "    indexes = np.where(two_hot_vec==1)[0]\n",
    "    return index_to_letter[indexes[0]] + index_to_letter[indexes[1]]\n",
    "\n",
    "def convert_indexes_to_char(indexes):\n",
    "    return index_to_letter[indexes[0]] + index_to_letter[indexes[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters, diacritics = getLettersAndDiacritics()\n",
    "# perhabs there is a problem here with the arrangement\n",
    "lettersAndDiacritics = letters + diacritics\n",
    "index_to_letter = dict((i, c) for i, c in enumerate(lettersAndDiacritics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(100, preds, 1)/100 \n",
    "    out1 = np.random.choice(range(42),1, p=probas.ravel())\n",
    "    out2 = np.random.choice(range(42),1, p=probas.ravel())\n",
    "    dia = [0, 38, 39, 40, 41, 42]\n",
    "    while(out1==out2 or (out1 in dia  and out2 in dia)):\n",
    "        out2 = np.random.choice(range(42),1, p=probas.ravel())\n",
    "\n",
    "    return [out1[0], out2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model, Tx=40, n_x=42):\n",
    "    generated = ''\n",
    "    # sentence = text[start_index: start_index + Tx]\n",
    "    # sentence = '0'*Tx\n",
    "    # usr_input = input(\"Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: \")\n",
    "    # zero pad the sentence to Tx characters.\n",
    "    usr_input = 'بلب'\n",
    "\n",
    "    sentence = ('{0:0<' + str(Tx) + '}').format(usr_input).lower()\n",
    "    generated += usr_input\n",
    "\n",
    "    sys.stdout.write(\"\\n\\nHere is your poem: \\n\\n\")\n",
    "    sys.stdout.write(usr_input)\n",
    "    for i in range(100):\n",
    "        x_pred = np.zeros((1, Tx, n_x))\n",
    "        two_hot_vec = np.squeeze(convert_to_two_hot(sentence.split('0')[0]))\n",
    "        x_pred[0][:len(two_hot_vec)] = two_hot_vec\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "#         print(x_pred)\n",
    "#         print(np.argmax(preds))\n",
    "\n",
    "        next_index = sample(preds, temperature=1.0)\n",
    "#         print(next_index)\n",
    "        next_char = convert_indexes_to_char(next_index)\n",
    "        generated += next_char\n",
    "        sentence = sentence + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "بلب بدَْجه ُاْرْىسع كْوَبَْاَْْاِْذْاملْاََْاَْا ْىَنجْْنِبَْر تْاْعْْع ىْاش ُاَْْاْاَيَنَُْتَْْو َْى يَْ َ َْب املْامْايِاَْ اَنْاظْْو َْىْررِ لَْْنْذْقُآْنْروَْاْحتَََُْاُْرَََْْْئْْرلبءْنَْاْا رْهْدَْ"
     ]
    }
   ],
   "source": [
    "generate_output(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
